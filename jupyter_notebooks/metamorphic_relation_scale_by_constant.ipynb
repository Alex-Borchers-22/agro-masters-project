{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23048bd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load in csvOut.csv data (holds image name & classification)\n",
    "import csv\n",
    "import os #to get all picture in directory\n",
    "from PIL import Image #to open images\n",
    "import numpy as np #load in numpy module\n",
    "import sys\n",
    "\n",
    "# loads in full csvOut data (name & classification)\n",
    "with open('..//annotations_handheld.csv', newline='') as csvfile:\n",
    "    cls_full = list(csv.reader(csvfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f895b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all files in directory\n",
    "path = \"..//images_handheld_resized\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "# Initialize list of 'keys'\n",
    "keys = [\"regular\", \"double\", \"half\"]\n",
    "\n",
    "# Initialize lists to hold bitmap information for each image\n",
    "bitmap = {}\n",
    "for key in keys:\n",
    "    bitmap[key] = []\n",
    "\n",
    "# list of classifications\n",
    "cls = []\n",
    "\n",
    "# loop through files and get bit map for each (save as object where filename => bitmap for r,g,b)\n",
    "for index, file in enumerate(cls_full):\n",
    "    \n",
    "    # stop at 100 files for time being\n",
    "    if index == 100:\n",
    "        break\n",
    "    \n",
    "    # push classification to list\n",
    "    cls.append(file[1])\n",
    "    \n",
    "    # method found https://stackoverflow.com/questions/46385999/transform-an-image-to-a-bitmap\n",
    "    img = Image.open(path + \"\\\\\" + file[0])\n",
    "    \n",
    "    # resize image\n",
    "    #small_img = img.resize((600, 400))\n",
    "    #smaller_img = img.resize((300, 200))\n",
    "    smallest_img = img.resize((120, 80))\n",
    "    \n",
    "    # merge channels in new order\n",
    "    bitmap['regular'].append(np.array(smallest_img).reshape(-1))\n",
    "    bitmap['double'].append(np.array(smallest_img).reshape(-1))\n",
    "    bitmap['half'].append(np.array(smallest_img).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c052113b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert bitmaps to indexed np array\n",
    "bitmap_arr = {}\n",
    "for key in keys:\n",
    "    bitmap_arr[key] = np.array(bitmap[key])\n",
    "\n",
    "# convert classifications to numpy array\n",
    "cls_np = np.array(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34c3e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust by some constant\n",
    "bitmap_arr['double'] = bitmap_arr['double'] * 2\n",
    "bitmap_arr['half'] = bitmap_arr['half'] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc297c9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 226,  54, ..., 130, 120, 108],\n",
       "       [ 98, 164, 110, ..., 130, 120, 110],\n",
       "       [150, 218, 154, ..., 202,  70, 104],\n",
       "       ...,\n",
       "       [118, 202,  48, ..., 140, 170, 140],\n",
       "       [148, 138, 112, ...,  70,  62,  58],\n",
       "       [188, 204, 190, ..., 130, 120, 108]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitmap_arr['regular']\n",
    "#bitmap_arr['double']\n",
    "#bitmap_arr['half']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db41d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training model (load necessary libraries)\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize dictionary to hold training & test data\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "\n",
    "# loop through keys split data into training and testing sets\n",
    "for key in keys: \n",
    "    X_train[key], X_test[key], y_train[key], y_test[key] = train_test_split(bitmap_arr[key], cls_np, test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "424cd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dictionary to hold predictions\n",
    "y_pred = {}\n",
    "\n",
    "# loop through keys, create SVM model and get classification prediction\n",
    "for key in keys: \n",
    "    model = svm.SVC(kernel=\"poly\", C=0.1, degree=2, coef0=0, gamma=\"scale\")\n",
    "    model.fit(X_train[key], y_train[key])\n",
    "    y_pred[key] = model.predict(X_test[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a9dae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metamorphic relation does not hold.\n"
     ]
    }
   ],
   "source": [
    "# check if metamorphic relations hold\n",
    "c1 = np.array_equal(y_pred['regular'], y_pred['double'])\n",
    "c2 = np.array_equal(y_pred['double'], y_pred['half'])\n",
    "\n",
    "if c1 & c2:\n",
    "    print(\"Metamorphic relation holds.\")\n",
    "else:\n",
    "    print(\"Metamorphic relation does not hold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1adb0975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'B', 'B', 'H', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'H', 'H', 'B', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred['regular']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d368cc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'B', 'B', 'H', 'B', 'B', 'B', 'H', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'H', 'B', 'B', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred['double']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d40c200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'B', 'B', 'H', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'H', 'H', 'B', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred['half']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bcb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
